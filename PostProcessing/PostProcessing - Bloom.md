## Bloom 原理
Bloom的实现原理大致分为三步:  
1. 对需要处理的图像经过亮度提取, 并且通过一个阙值来控制亮度 
2. 对经过亮度提取后的图像进行模糊处理
	我们不会去对原图直接进行模糊，因为原图的尺寸比较大，且blur之后又是一张太清晰的低频图像，因此我们会再得到原图之后，进行一个降采样（更低分辨率）再进行模糊
1. 最后再叠加原图和模糊处理后的图像,输出即可

#### Bloom 与 HDR 的关系

开启HDR后，ColorBuffer里则会存储更多的数据，我们拿到更高精度的数据去处理图像的时候，那么得到的也将是更高精度的结果

## 高质量泛光

> 摘自 [高质量泛光（bloom）从理论到实战](https://zhuanlan.zhihu.com/p/525500877)

高质量的泛光需要满足以下几个特点
- 发光物边缘向外 “扩张” 的足够大
- 发光物中心足够亮（甚至超过 1.0 而被 clamp 成白色）
- 该亮的地方（灯芯、火把）要亮，不该亮的地方（白色墙壁、皮肤）不亮

### 快速的大范围模糊

使 *光晕扩得足够大* 的处理方案

> 要想光晕扩的足够大，第一件事情就是扩大模糊的范围。一种非常简单的思路就是死命加大滤波盒的尺寸，使用一个巨大的 kernal 对纹理进行模糊。但是性能上肯定是吃不消，单 pass 的纹理采样次数是 N^2 而双 pass 是 N+N
> 
> 此外还有一个问题，在处理高分辨率纹理时你需要等比地增加滤波盒的尺寸，才能形成同等大小的模糊。比如在 1000x1000 分辨率下用 250 像素的 kernal，模糊的结果占 1/4 屏幕，当分辨率增加到 2000x2000 的时候，要使用 500 像素的 kernal 才能达到同样的效果
> 
> 回到模糊的问题，模糊滤波的本质是查询 kernal 范围内的所有像素并加权平均，即范围查询问题。在计算机图形学中实现快速范围查询，通常会请到老朋友 Mipmap 出场。Mipmap 将图像大小依次折半形成金字塔，mip[i] 中的单个像素代表了 mip[i-1] 中的 2x2 像素块均值，也代表 mip[i-2] 中的 4x4 像素块均值
> 
> 通过查询高 level 的 mipmap 可以在常数时间内查询大范围的源纹理。在 (w/4, h/4) 的贴图上做 3x3 滤波，近似于在 (w, h) 的贴图上做 12x12 的滤波。为此需要创建 size 逐级递减的纹理，并使用 downSampler 着色器将 mip[i-1] 下采样到 mip [i]，以 Unity 为例，在 OnRenderImage 中一个最简单的下采样 mip 串实现

简单来说，就是渐进式的降采样与上采样

**一个概念** ：渐进式的降采样与上采样，一般我们为了拿到比屏幕分辨率小的图像时会这样做
每一次降低一倍的分辨率，然后迭代N次，然后每次再提升一半分辨率，迭代N次。为什么要这样做，迭代两次跟直接除以10有啥区别？这其实是利用了引擎的双线性过滤对图像做一个间接的模糊

### 描绘中心高亮区域

> 使用下采样生成大范围的模糊仅仅是第一步，直接将最高层级 mip 叠加到图像上虽然能够产生足够大的光晕扩散，但是发光物的中心区域不够明亮。此外，发光物和泛光之间没有过度而是直接跳变，从高亮区域跳到低亮度区域显得非常不自然
> 不管使用何种滤波器，本质上都是在做加权平均。只要一平均，就有人拖后腿！每次模糊都会降低源图像的亮度，并将这些亮度分摊到周围的纹理。边缘的跳变来自于高层级 mip 和原图之间亮度差距过大
> ![Alt Text](Textures/20240501230853.png)
> 为了实现发光物和最高层 mip 之间的过渡，我们需要叠加所有的 mip 层级到原图上。因为 mip[i] 是基于 mip[i-1] 进行计算的，相邻层级之间相对连续则不会产生跳变：
> ![](https://pic2.zhimg.com/80/v2-502d2c8ff257cea0f674949dacae7529_1440w.webp)
> 较低的 mip 层级模糊范围小且亮度高，主要负责发光物中心的高亮，较高的 mip 层级模糊范围大且亮度低，主要负责发光物边缘的泛光。叠加所有的 mipmap 就能同时达到高质量泛光的两个要求，即够亮与够大

### 处理方块图样
> 因为我们直接从 mipmap 链中采样到全分辨率，很难免会出现方块状的 pattern，因为最高级别的 mip 分辨率小到个位数
> 可以通过模糊滤波来解决方块图样。值得注意的是不能直接对小分辨率的高阶 mip 进行滤波，因为分辨率太小，不管怎么滤波，上采样到 full resolution 的时候都会有方块。除非滤波发生在高分辨率纹理
> 但是高分辨率纹理上一大块区域都对应低分辨率 mip 上的同一个 texel，如果 kernal 不够大那么做 filter 的时候查询的值都是同一个 texel，这意味着在高分辨率纹理上要使用超大的滤波盒才能消除这些方块。
> 问题又回到了如何使用廉价的小尺寸滤波盒实现大范围模糊的问题。和下采样时类似，采样逐级递进的方式对低分辨率的 mip 链进行上采样。将 mip[i] 上采样到 mip[i-1]，再和 mip[i-1] 本身叠加得到新的 mip[i-1]

即逐层上采样

>进行这个操作需要额外创建一组 RenderTexture，下面是下采样 mip 链（RT_BloomDown）和上采样 mip 链（RT_BloomUp）之间的数据倒腾关系，以 964x460 分辨率和 N=7 次为例：
> ![](https://pic2.zhimg.com/80/v2-1be5032cc27dd55f156c4f6508f4f639_1440w.webp)

### 和闪烁对抗

> 如果熟悉 PBR 流程的话，不难想到 specular 的 BRDF 在 roughness 非常小、NdotL 接近 1.0 的时候，会输出极大的数值，尤其是当光源的强度足够高时。即高光部分非常亮，如果使用了法线贴图等高频法线信息，会导致画面闪烁的很厉害
> 对此 COD 的方案是在 mip0 到 mip1 即第一次下采样时，加入额外的权重来试图抹平因法线贴图碰巧 NdotL 很接近 1.0 而引起单个超高亮像素。这个做法叫做 Karis Average：
> ![](https://pic4.zhimg.com/80/v2-0d0a6751f35c738d565268a6510897bf_1440w.webp)

### 更好的滤波盒
> 在上下采样都使用 5x5 的高斯滤波盒显得有些奢侈。采样纹理是非常昂贵的操作，GPU 需要经过数百个时钟周期才能完成。直接使用 2x2 的 box 虽然足够快速，但会有很明显的 pattern
> 在 COD 的分享中使用了更为小巧的滤波盒，下采样时按照 2x2 一组在进行采样。采样共 5 组，并按照一定的权重加权。这个滤波盒在高斯模糊和 2x2 box 之间进行了均衡，既保证了效率又保证了质量

上述就是如何制作一个高质量泛光的大致流程和方案

## 实操
